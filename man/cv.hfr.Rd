% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/cv.hfr.R
\name{cv.hfr}
\alias{cv.hfr}
\title{Cross validation for a hierarchical feature regression}
\usage{
cv.hfr(
  x,
  y,
  nu_grid = seq(0, 1, by = 0.1),
  q = NULL,
  intercept = TRUE,
  standardize = TRUE,
  nfolds = 10,
  foldid = NULL,
  ...
)
}
\arguments{
\item{x}{Input matrix, of dimension \eqn{(N\times p)}{(N x p)}; each row is an observation vector.}

\item{y}{Response variable.}

\item{nu_grid}{A vector of target effective degrees of freedom of the regression.}

\item{q}{The quantile cut-off (in terms of information contributed) above which to consider levels in the hierarchy.}

\item{intercept}{Should intercept be fitted (default=TRUE).}

\item{standardize}{Logical flag for x variable standardization prior to fitting the model. The coefficients are always returned on the original scale. Default is \code{standardize=TRUE}.}

\item{nfolds}{The number of folds for k-fold cross validation (default=10).}

\item{foldid}{n optional vector of values between 1 and nfolds identifying what fold each observation is in. If supplied, nfolds can be missing.}

\item{...}{Additional arguments passed to \code{hclust}.}
}
\value{
A 'cv.hfr' regression object.
}
\description{
HFR is a regularized regression estimator that decomposes a least squares
regression along a semi-supervised hierarchical graph, and shrinks coefficients
along the branches of the tree. The algorithm leads to group shrinkage in the
regression parameters and a reduction in the effective model degrees of freedom.
}
\details{
This function fits an HFR to a grid of 'nu' hyperparameter values. The result is a
matrix of coefficients with one column for each hyperparameter. By evaluating all hyperparameters
in a single function, the speed of the algorithm can be improved substantially (e.g. by estimating
level-specific regressions only once).

When 'nfolds > 1', a cross validation is performed with shuffled data. Alternatively,
test slices can be passed to the function using the 'foldid' argument. The result
of the cross validation is given by 'best_nu' in the output object.
}
\examples{
x = matrix(rnorm(100 * 20), 100, 20)
y = rnorm(100)
fit = cv.hfr(x, y, nu_grid = seq(0, 1, by = 0.1))
coef(fit)

}
\references{
Pfitzinger, J. (2021).
Cluster Regularization via a Hierarchical Feature Regression.
arXiv 2107.04831[statML]
}
\seealso{
\code{hfr}, \code{coef} and \code{predict} methods
}
\author{
Johann Pfitzinger
}
